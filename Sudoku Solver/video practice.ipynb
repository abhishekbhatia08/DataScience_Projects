{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# Capturing the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "while(True):\n",
    "     ret, frame = cap.read()\n",
    "     cv2.imshow('frame', frame)\n",
    "    \n",
    "     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "         break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while(True):\n",
    "     ret, frame = cap.read()\n",
    "     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "     cv2.imshow('gray video', gray)\n",
    "    \n",
    "     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "         break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "\n",
    "    kernel = np.ones((5, 5), np.float32)/25\n",
    "    dst = cv2.filter2D(gray, -1, kernel)\n",
    "    blur = cv2.blur(gray, (5, 5))\n",
    "    gblur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    median = cv2.medianBlur(gray, 5)\n",
    "    bilateralFilter = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "\n",
    "    titles = ['image', '2D Convolution', 'blur', 'GaussianBlur', 'median', 'bilateralFilter']\n",
    "    images = [frame, dst, blur, gblur, median, bilateralFilter]\n",
    "      \n",
    "    for i in range(len(images)):\n",
    "         cv2.namedWindow(titles[i], cv2.WINDOW_NORMAL)\n",
    "         cv2.imshow(titles[i],images[i])\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    ret,th1 = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "    th2 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "                cv2.THRESH_BINARY,11,2)\n",
    "    th3 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                cv2.THRESH_BINARY,11,2)\n",
    "    titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "                'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "    images = [gray, th1, th2, th3]\n",
    "    for i in range(4):\n",
    "         cv2.namedWindow(titles[i], cv2.WINDOW_NORMAL)\n",
    "         cv2.imshow(titles[i],images[i])\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                cv2.THRESH_BINARY,11,2)\n",
    "    #kernel = np.ones((3,3),np.uint8)\n",
    "    #dilated = cv2.dilate(thresh,kernel)\n",
    "    #close=cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    canny = cv2.Canny(thresh, 200, 255, 1)\n",
    "\n",
    "    corners = cv2.goodFeaturesToTrack(canny,4,0.5,50)\n",
    "\n",
    "    for corner in corners:\n",
    "        x,y = corner.ravel()\n",
    "        cv2.circle(frame,(x,y),5,(36,255,12),-1)\n",
    "    cv2.imshow('c',canny)\n",
    "    cv2.imshow('t',frame)\n",
    " \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outer Grid Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIND ALL CONTOURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                cv2.THRESH_BINARY,11,2)\n",
    "    \n",
    "    contours,hier = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        if cv2.contourArea(contour) < 10000:\n",
    "            continue\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('f',frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larget Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                cv2.THRESH_BINARY,11,2)\n",
    "    \n",
    "    contour,hier = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_grille = None\n",
    "    maxArea = 0\n",
    "    for c in contour:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > 20000:\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            polygone = cv2.approxPolyDP(c, 0.01 * peri, True)\n",
    "            if area > maxArea and len(polygone) == 4:\n",
    "                contour_grille = polygone\n",
    "                maxArea = area\n",
    "    if contour_grille is not None:\n",
    "        cv2.drawContours(frame, [contour_grille], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('t',frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting perfect image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640.0\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import operator\n",
    "\n",
    "margin = 10\n",
    "case = 28 + 2*margin\n",
    "perspective_size = 9*case\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    p_frame = frame.copy()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "                cv2.THRESH_BINARY,11,2)\n",
    "    \n",
    "    contour,hier = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_grille = None\n",
    "    maxArea = 0\n",
    "    for c in contour:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > 20000:\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            polygone = cv2.approxPolyDP(c, 0.01 * peri, True)\n",
    "            if area > maxArea and len(polygone) == 4:\n",
    "                contour_grille = polygone\n",
    "                maxArea = area\n",
    "    if contour_grille is not None:\n",
    "        cv2.drawContours(frame, [contour_grille], 0, (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        corners = get_corners_from_contours(contour_grille, 4)\n",
    "        \n",
    "        pts1=np.float32(sort_corners(corners))\n",
    "        (tl, tr, br, bl) = pts1\n",
    "        width_A = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "        width_B = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "\n",
    "        # the height of our Sudoku board\n",
    "        height_A = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "        height_B = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "\n",
    "        # take the maximum of the width and height values to reach\n",
    "        # our final dimensions\n",
    "        max_width = max(int(width_A), int(width_B))\n",
    "        max_height = max(int(height_A), int(height_B))\n",
    "\n",
    "        # construct our destination points which will be used to\n",
    "        # map the screen to a top-down, \"birds eye\" view\n",
    "        dst = np.array([\n",
    "       [0, 0],\n",
    "        [max_width - 1, 0],\n",
    "      [max_width - 1, max_height - 1],\n",
    "        [0, max_height - 1]], dtype = \"float32\")\n",
    "\n",
    "        # calculate the perspective transform matrix and warp\n",
    "        # the perspective to grab the screen\n",
    "        perspective_transformed_matrix = cv2.getPerspectiveTransform(pts1, dst)\n",
    "        warp = cv2.warpPerspective(frame, perspective_transformed_matrix, (max_width, max_height))\n",
    "        orginal_warp = np.copy(warp)\n",
    "                \n",
    "    \n",
    "    cv2.imshow('f',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('p',warp)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corners_from_contours(contours, corner_amount=4, max_iter=200):\n",
    "\n",
    "    coefficient = 1\n",
    "    while max_iter > 0 and coefficient >= 0:\n",
    "        max_iter = max_iter - 1\n",
    "\n",
    "        epsilon = coefficient * cv2.arcLength(contours, True)\n",
    "\n",
    "        poly_approx = cv2.approxPolyDP(contours, epsilon, True)\n",
    "        hull = cv2.convexHull(poly_approx)\n",
    "        if len(hull) == corner_amount:\n",
    "            return hull\n",
    "        else:\n",
    "            if len(hull) > corner_amount:\n",
    "                coefficient += .01\n",
    "            else:\n",
    "                coefficient -= .01\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have 4 corners, locate the top left, top right, bottom left and bottom right corners\n",
    "def sort_corners(corners):\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "    corners = corners.reshape(4,2)\n",
    "    \n",
    "    # Find top left (sum of coordinates is the smallest)\n",
    "    sum = 10000\n",
    "    index = 0\n",
    "    for i in range(4):\n",
    "        if(corners[i][0]+corners[i][1] < sum):\n",
    "            sum = corners[i][0]+corners[i][1]\n",
    "            index = i\n",
    "    rect[0] = corners[index]\n",
    "    corners = np.delete(corners, index, 0)\n",
    "\n",
    "    # Find bottom right (sum of coordinates is the biggest)\n",
    "    sum = 0\n",
    "    for i in range(3):\n",
    "        if(corners[i][0]+corners[i][1] > sum):\n",
    "            sum = corners[i][0]+corners[i][1]\n",
    "            index = i\n",
    "    rect[2] = corners[index]\n",
    "    corners = np.delete(corners, index, 0)\n",
    "\n",
    "    # Find top right (Only 2 points left, should be easy\n",
    "    if(corners[0][0] > corners[1][0]):\n",
    "        rect[1] = corners[0]\n",
    "        rect[3] = corners[1]\n",
    "        \n",
    "    else:\n",
    "        rect[1] = corners[1]\n",
    "        rect[3] = corners[0]\n",
    "\n",
    "    rect = rect.reshape(4,2)\n",
    "    \n",
    "    return rect\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
